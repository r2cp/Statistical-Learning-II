{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR - *Forward propagation* y *backpropagation*\n",
    "\n",
    "Statistical Learning II\n",
    "\n",
    "Rodrigo Chang\n",
    "\n",
    "19000625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Librerías y funciones de activación y bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activación sigmoide\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "# Activación de escalón\n",
    "def heaviside(x):\n",
    "    return (x >= 0).astype(np.float)\n",
    "\n",
    "# Función de activación ReLU\n",
    "def ReLU(x):\n",
    "    return np.maximum(0., x)\n",
    "\n",
    "def ReLU_gradient(x):\n",
    "    return (x > 0).astype(np.float)\n",
    "\n",
    "def linearAct(x):\n",
    "    return x\n",
    "\n",
    "# Función para añadir el término de bias a la primera fila\n",
    "# x tiene shape (n, k)\n",
    "# Devuelve matriz con tamaño (n+1, k)\n",
    "def addBias(x):\n",
    "    return np.vstack((np.ones(x.shape[1]), x))\n",
    "\n",
    "# Función para quitar el término de bias de la primera fila\n",
    "# x tiene shape (n+1, k)\n",
    "# Devuelve matriz con tamaño (n, k)\n",
    "def removeBias(x):\n",
    "    return x[1:, :].reshape(-1, x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26894142, 0.5       , 0.73105858, 0.88079708])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid(np.array([-1, 0., 1., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU(np.array([-1, 0., 1., 2.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ReLU_gradient(np.array([-1, 0., 1., 2.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Conjunto de datos de entrenamiento\n",
    "Definimos el conjunto de datos de entrenamiento. En este caso, queremos que la red neuronal aprenda la función XOR, por lo tanto, utilizaremos dos entradas y sus respectivas salidas conocidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = np.array([[0., 0.], [0., 1.], [1., 0.], [1., 1.]])\n",
    "Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain = np.array([0., 1., 1., 0.]).reshape(-1, 1)\n",
    "Ytrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., 1.],\n",
       "        [0., 1., 0., 1.]]), array([[0., 1., 1., 0.]]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.T, Ytrain.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Matrices de pesos sinápticos\n",
    "Definimos los pesos sinápticos iniciales de la red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.15415817, -0.22765972,  0.00147032],\n",
       "       [ 0.08778565, -0.00696515,  0.20408783],\n",
       "       [ 0.01326903,  0.01138651, -0.08460882]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capa oculta 1\n",
    "k1 = 3\n",
    "Theta1 = np.random.normal(scale=0.1, size=(k1, 3))\n",
    "Theta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.16646132, -0.23252446,  0.12473551, -0.14228832],\n",
       "       [-0.04169177,  0.03146323, -0.1531307 , -0.00371119]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capa oculta 2\n",
    "k2 = 2\n",
    "Theta2 = np.random.normal(scale=0.1, size=(k2, k1+1))\n",
    "Theta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0512652 , 0.03846694, 0.12638179]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Capa de salida\n",
    "Theta3 = np.random.normal(scale=0.1, size=(1, 3))\n",
    "Theta3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## *Forward propagation* y cómputo de la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., 1.],\n",
       "        [0., 1., 0., 1.]]), (2, 4))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.T, Xtrain.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardProp(X, Theta1, Theta2, Theta3):\n",
    "    # Primera capa oculta\n",
    "    z_2 = np.matmul(Theta1, addBias(X))\n",
    "    a_2 = ReLU(z_2)\n",
    "    #print(\"a_2: \", a_2, \"\\n\")\n",
    "    # Segunda capa oculta\n",
    "    z_3 = np.matmul(Theta2, addBias(a_2))\n",
    "    a_3 = ReLU(z_3)\n",
    "    #print(\"a_3: \", a_3, \"\\n\")\n",
    "    # Capa de salida\n",
    "    z_4 = np.matmul(Theta3, addBias(a_3))\n",
    "    a_4 = linearAct(z_4)\n",
    "    return a_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09787489, -0.09787489, -0.09787489, -0.09787489]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardProp(Xtrain.T, Theta1, Theta2, Theta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3708145 , 0.37081451, 0.3708149 , 0.37081491]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardProp(Xtrain.T, Theta1_trained, Theta2_trained, Theta3_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.09787489]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardProp(np.array([100., 50.]).reshape(-1, 1), Theta1, Theta2, Theta3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## *Backpropagation* de un ejemplo\n",
    "Propagación del error hacia atrás utilizando el ejemplo $(0, 1)$ cuya salida debería ser $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [1.]]), array([[1.]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtrain[1, :].reshape(-1, 1)\n",
    "Ytest = Ytrain[1].reshape(-1,1)\n",
    "Xtest, Ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09787489]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Propagamos hacia adelante el ejemplo\n",
    "a_1 = addBias(Xtest)\n",
    "# Primera capa oculta\n",
    "z_2 = np.matmul(Theta1, a_1)\n",
    "a_2 = ReLU(z_2)\n",
    "# Segunda capa oculta\n",
    "a_2 = addBias(a_2)\n",
    "z_3 = np.matmul(Theta2, a_2)\n",
    "a_3 = ReLU(z_3)\n",
    "# Capa de salida\n",
    "a_3 = addBias(a_3)\n",
    "z_4 = np.matmul(Theta3, a_3)\n",
    "a_4 = linearAct(z_4)\n",
    "\n",
    "## Backpropagation\n",
    "# Computamos el error en la capa de salida: d_4\n",
    "d_4 = a_4 - Ytest\n",
    "d_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.],\n",
       "       [-0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Propagamos hacia atrás\n",
    "d_3 = np.matmul(Theta3.T[1:], d_4) * ReLU_gradient(z_3)\n",
    "d_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Propagamos hacia atrás\n",
    "d_2 = np.matmul(Theta2.T[1:, :], d_3) * ReLU_gradient(z_2)\n",
    "d_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrices de cambio\n",
    "Construimos las matrices de cambio, para la actualización de las matrices de pesos sinápticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.09787489,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Delta3 = np.matmul(d_4, a_3.T)\n",
    "Delta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Delta2 = np.matmul(d_3, a_2.T)\n",
    "Delta2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Delta1 = np.matmul(d_2, a_1.T)\n",
    "Delta1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Función de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30372719291614736"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(forwardProp(Xtrain.T, Theta1, Theta2, Theta3).T - Ytrain, 2).mean() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnCosto(X, Y, Theta1, Theta2, Theta3):\n",
    "    \n",
    "    # Número de ejemplos\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Definir el costo del conjunto con el MSE\n",
    "    error = forwardProp(X.T, Theta1, Theta2, Theta3).T - Y\n",
    "    # Función de costo\n",
    "    J = np.mean(np.power(error, 2)) / 2\n",
    "    \n",
    "    # Cómputo de los gradientes \n",
    "    Delta1 = np.zeros_like(Theta1)\n",
    "    Delta2 = np.zeros_like(Theta2)\n",
    "    Delta3 = np.zeros_like(Theta3)\n",
    "    \n",
    "    # Backpropagation para cada ejemplo\n",
    "    for i in range(m):\n",
    "        # Obtenemos el ejemplo i\n",
    "        Xi = X[i, :].reshape(-1, 1)\n",
    "        # Propagamos hacia adelante el ejemplo\n",
    "        a_1 = addBias(Xi)\n",
    "        # Primera capa oculta\n",
    "        z_2 = np.matmul(Theta1, a_1)\n",
    "        a_2 = ReLU(z_2)\n",
    "        # Segunda capa oculta\n",
    "        a_2 = addBias(a_2)\n",
    "        z_3 = np.matmul(Theta2, a_2)\n",
    "        a_3 = ReLU(z_3)\n",
    "        # Capa de salida\n",
    "        a_3 = addBias(a_3)\n",
    "        z_4 = np.matmul(Theta3, a_3)\n",
    "        a_4 = linearAct(z_4)\n",
    "    \n",
    "        # Computamos el error en la capa de salida y propagamos hacia atrás\n",
    "        d_4 = a_4 - Ytest\n",
    "        d_3 = np.matmul(Theta3.T[1:], d_4) * ReLU_gradient(z_3)\n",
    "        d_2 = np.matmul(Theta2.T[1:, :], d_3) * ReLU_gradient(z_2)\n",
    "        \n",
    "        # Matrices de cambio\n",
    "        Delta3 += np.matmul(d_4, a_3.T)\n",
    "        Delta2 += np.matmul(d_3, a_2.T)\n",
    "        Delta1 += np.matmul(d_2, a_1.T)\n",
    "    \n",
    "    Theta1_grad = Delta1 / m\n",
    "    Theta2_grad = Delta2 / m\n",
    "    Theta3_grad = Delta3 / m\n",
    "\n",
    "    return J, Theta1_grad, Theta2_grad, Theta3_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.22277226973590006, array([[ 0.00421663,  0.        ,  0.00210715],\n",
       "        [-0.00452077, -0.0022588 , -0.00225909],\n",
       "        [ 0.00257994,  0.00128909,  0.        ]]), array([[-0.03624286, -0.00280885, -0.00675172, -0.00034375],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ]]), array([[-0.94218203, -0.16048004,  0.        ]]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnCosto(Xtrain, Ytrain, Theta1, Theta2, Theta3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Implementación del gradiente en descenso para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenarNN(X, Y, k1=3, k2=2, epochs=100, lr=0.001, statusRate=50):\n",
    "    \n",
    "    # Número de features\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # Matrices de pesos sinápticos aleatorias\n",
    "    Theta1 = np.random.normal(scale=0.05, size=(k1, n+1))\n",
    "    Theta2 = np.random.normal(scale=0.05, size=(k2, k1+1))\n",
    "    Theta3 = np.random.normal(scale=0.05, size=(1, 3))\n",
    "    \n",
    "    # Iterar sobre el número de epochs\n",
    "    for j in range(1, epochs+1):\n",
    "        # Obtener el costo y los gradientes\n",
    "        J, Theta1_grad, Theta2_grad, Theta3_grad = nnCosto(X, Y, Theta1, Theta2, Theta3)\n",
    "        \n",
    "        if (j % statusRate == 0):\n",
    "            print(\"Iteración: %d,\\tCosto: %0.4f\" % (j, J))\n",
    "        \n",
    "        # Actualizar los pesos sinápticos\n",
    "        Theta1 += -lr * Theta1_grad\n",
    "        Theta2 += -lr * Theta2_grad\n",
    "        Theta3 += -lr * Theta3_grad\n",
    "\n",
    "    return Theta1, Theta2, Theta3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración: 500,\tCosto: 0.2300\n",
      "Iteración: 1000,\tCosto: 0.2096\n",
      "Iteración: 1500,\tCosto: 0.1922\n",
      "Iteración: 2000,\tCosto: 0.1776\n",
      "Iteración: 2500,\tCosto: 0.1653\n",
      "Iteración: 3000,\tCosto: 0.1552\n",
      "Iteración: 3500,\tCosto: 0.1469\n",
      "Iteración: 4000,\tCosto: 0.1402\n",
      "Iteración: 4500,\tCosto: 0.1350\n",
      "Iteración: 5000,\tCosto: 0.1310\n"
     ]
    }
   ],
   "source": [
    "Theta1_trained, Theta2_trained, Theta3_trained = entrenarNN(Xtrain, Ytrain, \n",
    "                                                            epochs=5000, lr=0.0001, statusRate=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39006019, 0.39005634, 0.39006708, 0.39005945]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardProp(Xtrain.T, Theta1_trained, Theta2_trained, Theta3_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración: 100,\tCosto: 0.2355\n",
      "Iteración: 200,\tCosto: 0.2310\n",
      "Iteración: 300,\tCosto: 0.2267\n",
      "Iteración: 400,\tCosto: 0.2224\n",
      "Iteración: 500,\tCosto: 0.2183\n",
      "Iteración: 600,\tCosto: 0.2144\n",
      "Iteración: 700,\tCosto: 0.2105\n",
      "Iteración: 800,\tCosto: 0.2068\n",
      "Iteración: 900,\tCosto: 0.2032\n",
      "Iteración: 1000,\tCosto: 0.1997\n",
      "Iteración: 1100,\tCosto: 0.1964\n",
      "Iteración: 1200,\tCosto: 0.1931\n",
      "Iteración: 1300,\tCosto: 0.1899\n",
      "Iteración: 1400,\tCosto: 0.1869\n",
      "Iteración: 1500,\tCosto: 0.1840\n",
      "Iteración: 1600,\tCosto: 0.1811\n",
      "Iteración: 1700,\tCosto: 0.1784\n",
      "Iteración: 1800,\tCosto: 0.1757\n",
      "Iteración: 1900,\tCosto: 0.1731\n",
      "Iteración: 2000,\tCosto: 0.1707\n",
      "Iteración: 2100,\tCosto: 0.1683\n",
      "Iteración: 2200,\tCosto: 0.1660\n",
      "Iteración: 2300,\tCosto: 0.1638\n",
      "Iteración: 2400,\tCosto: 0.1617\n",
      "Iteración: 2500,\tCosto: 0.1596\n",
      "Iteración: 2600,\tCosto: 0.1576\n",
      "Iteración: 2700,\tCosto: 0.1558\n",
      "Iteración: 2800,\tCosto: 0.1539\n",
      "Iteración: 2900,\tCosto: 0.1522\n",
      "Iteración: 3000,\tCosto: 0.1505\n",
      "Iteración: 3100,\tCosto: 0.1489\n",
      "Iteración: 3200,\tCosto: 0.1474\n",
      "Iteración: 3300,\tCosto: 0.1459\n",
      "Iteración: 3400,\tCosto: 0.1445\n",
      "Iteración: 3500,\tCosto: 0.1431\n",
      "Iteración: 3600,\tCosto: 0.1419\n",
      "Iteración: 3700,\tCosto: 0.1406\n",
      "Iteración: 3800,\tCosto: 0.1395\n",
      "Iteración: 3900,\tCosto: 0.1384\n",
      "Iteración: 4000,\tCosto: 0.1373\n",
      "Iteración: 4100,\tCosto: 0.1363\n",
      "Iteración: 4200,\tCosto: 0.1353\n",
      "Iteración: 4300,\tCosto: 0.1344\n",
      "Iteración: 4400,\tCosto: 0.1336\n",
      "Iteración: 4500,\tCosto: 0.1328\n",
      "Iteración: 4600,\tCosto: 0.1320\n",
      "Iteración: 4700,\tCosto: 0.1313\n",
      "Iteración: 4800,\tCosto: 0.1307\n",
      "Iteración: 4900,\tCosto: 0.1300\n",
      "Iteración: 5000,\tCosto: 0.1294\n"
     ]
    }
   ],
   "source": [
    "Theta1_trained, Theta2_trained, Theta3_trained = entrenarNN(Xtrain, Ytrain, \n",
    "                                                            epochs=5000, lr=0.0001, statusRate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.39006019, 0.39005634, 0.39006708, 0.39005945]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forwardProp(Xtrain.T, Theta1_trained, Theta2_trained, Theta3_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03480973, -0.02545688, -0.02837511],\n",
       "       [-0.07013853,  0.06595636, -0.02542802],\n",
       "       [ 0.04686075,  0.03639778, -0.06366123]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta1_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05497828, -0.05486433,  0.01006399,  0.08805007],\n",
       "       [-0.0012665 ,  0.00521325, -0.044771  , -0.0633429 ]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta2_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38997452, 0.00149783, 0.10637533]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta3_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
